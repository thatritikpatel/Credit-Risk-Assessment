# -*- coding: utf-8 -*-
"""Default of Credit Card Clients Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qv-HdpiRZzRHvbdBiqd5E2H_vvzFa65V
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder

data = pd.read_csv("UCI_Credit_Card.csv")

data.head()

data.info()

data.shape

print(data.describe())

"""#### Handle Missing Values

"""

print(data.isnull().sum())

"""No missing values found"""

data.duplicated().sum()

"""No duplicates row found

# Univariate Analysis

## Numerical Data:
"""

data.info()

data.replace({'SEX': {1 : 'MALE', 2 : 'FEMALE'}, 'EDUCATION' : {1 : 'graduate school', 2 : 'university', 3 : 'high school', 4 : 'others'}, 'MARRIAGE' : {1 : 'married', 2 : 'single', 3 : 'others'}}, inplace = True)

data.info()

#renaming for better convinience
data.rename(columns={'default.payment.next.month': 'IsDefaulter'}, inplace=True)

# Get numerical columns
numerical_cols = data.select_dtypes(include=['number']).columns.tolist()

# Get categorical columns
categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE']


print("Numerical columns:", numerical_cols)
print("Categorical columns:", categorical_cols)

# Loop through numerical columns and create separate histograms with KDE
for col in numerical_cols:
    plt.figure(figsize=(8, 6))
    sns.histplot(data[col], bins = 30, kde=True)
    plt.title(f'Histogram with KDE for {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

"""## Categorical Data:

"""

data['SEX'].value_counts()

data['EDUCATION'].value_counts()

"""As we can see in dataset we have values like 5,6,0 as well for which we are not having description so we can add up them in 4, which is Others.


"""

fil = (data['EDUCATION'] == 5) | (data['EDUCATION'] == 6) | (data['EDUCATION'] == 0)
data.loc[fil, 'EDUCATION'] = "others"
data['EDUCATION'].value_counts()

data['MARRIAGE'].value_counts()

"""We have few values for 0, which are not determined . So I am adding them in Others category.


"""

fil = data['MARRIAGE'] == 0
data.loc[fil, 'MARRIAGE'] = "others"
data['MARRIAGE'].value_counts()

# Loop through each categorical column and create a bar plot
for col in categorical_cols:
    plt.figure(figsize=(8, 6))
    data[col].value_counts().plot(kind='bar')
    plt.title(f'Bar Plot for {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.show()

"""## OBSERVATIONS:

1. Most people who have taken loans are in the age range of 25 to 30.
2. More than 20,000 customers have defaulted their payment
3. Dataset contains more Females than male
4. Dataset has more university graduates compared to other education
5. The dataset contains more number of singles than people who are married.

# Bivariate Analysis
"""

for col in categorical_cols:
  plt.figure(figsize=(10,5))
  fig, axes = plt.subplots(ncols=2,figsize=(13,8))
  data[col].value_counts().plot(kind="pie",ax = axes[0],subplots=True)
  sns.countplot(x = col, hue = data["IsDefaulter"] , data = data[categorical_cols])

"""OBSERVATIONS:

1. The majority of credit card holders are female, resulting in a higher proportion of female defaulters.
2. Defaulters include a higher proportion of educated individuals (those who attended graduate school or university).
3. A higher proportion of defaulters are single.

"However, no definitive conclusions can be drawn from these observations because the dataset predominantly consists of these groups."

# Feature Engineering and Preprocessing
"""

data.replace({'SEX': {1 : 'MALE', 2 : 'FEMALE'}, 'EDUCATION' : {1 : 'graduate school', 2 : 'university', 3 : 'high school', 4 : 'others'}, 'MARRIAGE' : {1 : 'married', 2 : 'single', 3 : 'others'}}, inplace = True)

#drop ID column
data.drop('ID', axis=1, inplace=True)

# 1. One-Hot Encoding (for MARRIAGE)
one_hot = pd.get_dummies(data['MARRIAGE'], prefix='MARRIAGE')
data = pd.concat([data, one_hot], axis=1)
data.drop('MARRIAGE', axis=1, inplace=True)
data.head()

# 2. Label Encoding (for SEX)
le = LabelEncoder()
data['SEX'] = le.fit_transform(data['SEX'])

print("\nAfter Label Encoding SEX:")
data.head()

# 3. Ordinal Encoding (for EDUCATION)
education_order = ['others', 'high school', 'graduate school', 'university']
oe = OrdinalEncoder(categories=[education_order])
data['EDUCATION'] = oe.fit_transform(data[['EDUCATION']])

data.info()

"""# Data splitting"""

X = data.drop('IsDefaulter', axis=1)
y = data['IsDefaulter']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""### Data rebalancing with SMOTE

Since we have identified that our dataset is imbalanced, we are using SMOTE (Synthetic Minority Oversampling Technique) to address this issue.
"""

# Apply SMOTE to the training data
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

"""### Feature Scaling"""

# 1. StandardScaler
scaler = StandardScaler()
X_train_standard = scaler.fit_transform(X_train_resampled)
X_test_standard = scaler.transform(X_test)

"""## Model building and testing"""

from sklearn.naive_bayes import GaussianNB
clf = GaussianNB()
clf.fit(X_train_standard,y_train_resampled)

y_pred=clf.predict(X_test_standard)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_pred)*100

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score
import time


# Define classifiers
classifiers = {
    "Logistic Regression": LogisticRegression(random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "Extreme Gradient Boosting": XGBClassifier(random_state=42),
    "SVM": SVC(random_state=42),
    "Naive Bayes": GaussianNB(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Neural Network": MLPClassifier(random_state=42, max_iter=1000)
}

# Function to evaluate model
def evaluate_model(model, X_train, y_train, X_test, y_test):
    # Start timer
    start_time = time.time()

    # Train the model
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)

    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred)

    # Perform cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)

    # End timer
    end_time = time.time()

    # Calculate training time
    train_time = end_time - start_time

    return accuracy, cv_scores.mean(), train_time

# Evaluate each classifier
results = []

for name, clf in classifiers.items():
    accuracy, cv_score, train_time = evaluate_model(clf, X_train_standard, y_train_resampled, X_test_standard, y_test)
    results.append((name, accuracy, cv_score, train_time))

# Sort results by accuracy
results.sort(key=lambda x: x[1], reverse=True)

# Print results
print("Classifier Performance Comparison:")
print("-----------------------------------")
for name, accuracy, cv_score, train_time in results:
    print(f"{name}:")
    print(f"  Test Accuracy: {accuracy:.4f}")
    print(f"  Cross-Validation Score: {cv_score:.4f}")
    print(f"  Training Time: {train_time:.4f} seconds")
    print("-----------------------------------")

# Get the best performing model
best_model_name = results[0][0]
best_model = classifiers[best_model_name]

# Train the best model
best_model.fit(X_train_standard, y_train_resampled)

# Make predictions
y_pred = best_model.predict(X_test_standard)

# Print detailed classification report for the best model
print(f"\nDetailed Classification Report for {best_model_name}:")
print(classification_report(y_test, y_pred))

feature_names = data.drop(columns=['IsDefaulter']).columns.tolist()

# Feature importance for tree-based models
if best_model_name in ["Decision Tree", "Random Forest", "Gradient Boosting","Extreme Gradient Boosting"]:
    importances = best_model.feature_importances_
    feature_importances = list(zip(feature_names, importances))
    feature_importances.sort(key=lambda x: x[1], reverse=True)

    print(f"\nTop 10 Feature Importances for {best_model_name}:")
    for i, (feature, importance) in enumerate(feature_importances[:10], 1):
        print(f"{i}. {feature}: {importance*100:.2f}%")

import numpy as np
import pandas as pd
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from scipy.stats import randint, uniform


# Define the parameter distributions
param_dist = {
    'n_estimators': randint(100, 1000),
    'learning_rate': uniform(0.01, 0.3),
    'max_depth': randint(3, 10),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10),
    'subsample': uniform(0.6, 0.4),
    'max_features': ['sqrt', 'log2', None]
}

# Create a base model
gb_base = GradientBoostingClassifier(random_state=42)

# Instantiate the random search model
random_search = RandomizedSearchCV(estimator=gb_base, param_distributions=param_dist,
                                   n_iter=20, cv=3, verbose=2, random_state=42, n_jobs=-1)

# Fit the random search to the data
random_search.fit(X_train_standard, y_train_resampled)

# Print the best parameters and score
print("Best parameters found: ", random_search.best_params_)
print("Best cross-validation score: {:.2f}".format(random_search.best_score_))

# Get the best model
best_gb = random_search.best_estimator_

# Make predictions using the best model
y_pred = best_gb.predict(X_test_standard)

# Print the model's performance
print("\nBest Model Performance on Test Set:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Feature importance
feature_importance = best_gb.feature_importances_
feature_names = X.columns
feature_importance_sorted = sorted(zip(feature_importance, feature_names), reverse=True)

print("\nTop 10 Most Important Features:")
for importance, name in feature_importance_sorted[:10]:
    print(f"{name}: {importance:.4f}")

# Plot feature importances
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})
importances = importances.sort_values('importance', ascending=False).head(20)
plt.bar(importances['feature'], importances['importance'])
plt.title('Feature Importances')
plt.xlabel('Features')
plt.ylabel('Importance')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""# Building model with best parameters"""

model = GradientBoostingClassifier(
    learning_rate=0.03654775061557585,
    max_depth=9,
    max_features='sqrt',
    min_samples_leaf=8,
    min_samples_split=17,
    n_estimators=848,
    subsample=0.7085396127095583,
    random_state=42  # for reproducibility
)

model.fit(X_train_standard, y_train_resampled)

# Make predictions using the best model
y_pred = best_gb.predict(X_test_standard)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

"""Observation:- Based on the observed accuracies, we can conclude that the GradientBoostingClassifier, when used with its default parameters, is outperforming the model obtained through RandomizedSearchCV."""

import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns


# Fetch the column names from the data

feature_names = X.columns


# Create the GradientBoostingClassifier with specified hyperparameters
gb_classifier = GradientBoostingClassifier(
        random_state=42
)

# Fit the model
gb_classifier.fit(X_train_standard, y_train_resampled)

# Make predictions
y_pred = gb_classifier.predict(X_test_standard)

# Calculate various metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

# Feature importance
feature_importance = gb_classifier.feature_importances_
feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})
feature_importance_df = feature_importance_df.sort_values('importance', ascending=True)

plt.figure(figsize=(12, 8))
plt.barh(feature_importance_df['feature'], feature_importance_df['importance'])
plt.xlabel('Feature Importance')
plt.title('Feature Importance for Gradient Boosting Classifier')
plt.tight_layout()
plt.show()

# Learning curve
from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(
    gb_classifier, X_train_standard, y_train_resampled, cv=5, n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10), scoring="accuracy"
)

train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, label="Training score", color="blue", marker='o')
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color="blue")
plt.plot(train_sizes, test_mean, label="Cross-validation score", color="red", marker='s')
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.15, color="red")
plt.title("Learning Curve for Gradient Boosting Classifier")
plt.xlabel("Training Examples")
plt.ylabel("Accuracy Score")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

import pickle

with open('Default of Credit Card Clients.pkl', 'wb') as file:
    pickle.dump(gb_classifier, file)

import pickle

with open('Default of Credit Card Clients.pkl', 'rb') as file:
    loaded_model = pickle.load(file)

loaded_model